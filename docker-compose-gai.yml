version: '3.8'

services:
  # -------------------------
  # 1. Ollama (‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ)
  # -------------------------
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_storage:/root/.ollama

      - ./backend/src/llm/entrypoint.sh:/entrypoint.sh
    entrypoint: [ "/bin/bash", "-c", "tr -d '\\r' < /entrypoint.sh | bash" ]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    networks:
      - ai-net

  # -------------------------
  # 2. GPUStack Manager (‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤ - ‡πÑ‡∏°‡πà‡∏°‡∏µ GPU) üß†
  # -------------------------
  gpustack:
    image: gpustack/gpustack:latest
    ports:
      - "10101:80"
    volumes:
      - gpustack_data:/var/lib/gpustack
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤
      - GPUSTACK_TOKEN=mysecrettoken123
      - GPUSTACK_ADMIN_PASSWORD=Qwerty@1234
      # ‚ùå ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏™‡πà SERVER_URL ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
    networks:
      - ai-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  # -------------------------
  # 3. GPUStack Worker (‡∏•‡∏π‡∏Å‡∏ô‡πâ‡∏≠‡∏á - ‡∏°‡∏µ GPU) üí™
  # -------------------------
  gpustack-worker:
    image: gpustack/gpustack:latest
    # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡∏¥‡∏î Port ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏°‡∏±‡∏ô‡∏à‡∏∞‡∏ß‡∏¥‡πà‡∏á‡πÑ‡∏õ‡∏´‡∏≤‡∏´‡∏±‡∏ß‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏≠‡∏á
    volumes:
      # ‡πÅ‡∏¢‡∏Å Volume Cache ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏≠‡∏Å‡∏°‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡∏Å‡πá‡πÑ‡∏î‡πâ (‡πÅ‡∏¢‡∏Å‡∏ä‡∏±‡∏ß‡∏£‡πå‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á Lock)
      - gpustack_worker_data:/var/lib/gpustack
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏•‡∏π‡∏Å‡∏ô‡πâ‡∏≠‡∏á
      - GPUSTACK_TOKEN=mysecrettoken123
      - GPUSTACK_SERVER_URL=http://gpustack:80
      - GPUSTACK_WORKER_NAME=docker-worker-1
      # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö NVIDIA
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    depends_on:
      - gpustack
    networks:
      - ai-net

  # -------------------------
  # 4. Backend
  # -------------------------
  backend:
    build:
      context: ./backend
      args:
        GUARDRAILS_TOKEN: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJpSlNlN3ZhNExSbUpxbkZOZUV6VEt0eEZHY1dXdFVuTyIsImFwaUtleUlkIjoiMzEzZGFjNmQtZDE3Yy00OGZkLTllNTItZjdhZDM1N2RjN2U2Iiwic2NvcGUiOiJyZWFkOnBhY2thZ2VzIiwicGVybWlzc2lvbnMiOlsidGhyZWF0X3Rlc3Rlcl9pbnZpdGU6dHJ1ZSJdLCJpYXQiOjE3NzA4NzA2NjcsImV4cCI6NDkyNDQ3MDY2N30.DOijp5oC0pZZFhmrRkXGw00GlNV3dnWfXOgbLtBIofs
    ports:
      - "8000:8000"
    volumes:
      - ./backend/src:/app/src
    environment:
      - OLLAMA_URL=http://ollama:11434
      - GUARD_ENGINE=guardrails_ai
      - GPUSTACK_URL=http://gpustack:80/v1
      - GPUSTACK_API_KEY=mysecrettoken123
    depends_on:
      - gpustack
    networks:
      - ai-net

  # -------------------------
  # 5. Frontend
  # -------------------------
  frontend:
    build:
      context: ./frontend
    ports:
      - "5173:5173"
    volumes:
      - ./frontend/src:/app/src
      - /app/node_modules
    environment:
      - VITE_API_URL=http://localhost:8000
    depends_on:
      - backend
    networks:
      - ai-net

volumes:
  ollama_storage:
  gpustack_data:
  gpustack_worker_data: # ‡πÄ‡∏û‡∏¥‡πà‡∏° Volume ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Worker

networks:
  ai-net:
    driver: bridge