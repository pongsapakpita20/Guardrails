import requests
import os
from typing import List
from .base import BaseLLMService

class OllamaService(BaseLLMService):
    def __init__(self):
        # à¸­à¹ˆà¸²à¸™ URL à¸ˆà¸²à¸ Environment (à¸«à¸£à¸·à¸­à¹ƒà¸Šà¹‰ default)
        self.base_url = os.getenv("OLLAMA_URL", "http://ollama:11434")

    def get_models(self) -> List[str]:
        """à¸¢à¸´à¸‡à¹„à¸›à¸–à¸²à¸¡ Ollama à¸§à¹ˆà¸²à¸¡à¸µà¹‚à¸¡à¹€à¸”à¸¥à¸­à¸°à¹„à¸£à¸šà¹‰à¸²à¸‡"""
        try:
            res = requests.get(f"{self.base_url}/api/tags", timeout=5)
            if res.status_code == 200:
                data = res.json()
                # à¸”à¸¶à¸‡à¹€à¸‰à¸žà¸²à¸°à¸Šà¸·à¹ˆà¸­à¹‚à¸¡à¹€à¸”à¸¥à¸­à¸­à¸à¸¡à¸²
                return [model["name"] for model in data.get("models", [])]
            return []
        except Exception as e:
            print(f"âš ï¸ Ollama Error: {e}")
            return []

    async def generate(self, prompt: str, system_prompt: str = "", model_name: str = "") -> str:
        payload = {
            "model": model_name,
            "prompt": prompt,
            "system": system_prompt,
            "stream": False
        }
        
        print(f"ðŸš€ Sending to Ollama ({model_name})...")
        try:
            res = requests.post(f"{self.base_url}/api/generate", json=payload, timeout=120)
            if res.status_code == 200:
                return res.json().get("response", "")
            else:
                return f"Error: {res.status_code} - {res.text}"
        except Exception as e:
            return f"Connection Error: {str(e)}"