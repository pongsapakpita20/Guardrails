from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Dict, List, Optional

# ‚úÖ ‡πÉ‡∏ä‡πâ Factory ‡πÅ‡∏ó‡∏ô active_engine ‡∏ï‡∏±‡∏ß‡πÄ‡∏Å‡πà‡∏≤
from .engines.factory import EngineFactory
from .engines.base import SwitchInfo
from .llm.factory import LLMFactory
app = FastAPI(title="AI Guardrails Gateway")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==========================================
# 1. Endpoint ‡πÉ‡∏´‡∏°‡πà: ‡∏Ç‡∏≠‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ Framework ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
# ==========================================
@app.get("/frameworks")
async def get_frameworks():
    """‡∏™‡πà‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ Engine ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏°‡∏µ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ó‡∏≥ Dropdown"""
    return EngineFactory.get_available_engines()

# ==========================================
# 2. Endpoint ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏Ç‡∏≠‡∏™‡∏ß‡∏¥‡∏ï‡∏ä‡πå (‡∏ï‡∏≤‡∏° Framework ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å)
# ==========================================
@app.get("/config/switches", response_model=List[SwitchInfo])
async def get_switches(framework_id: str = Query("guardrails_ai", description="ID ‡∏Ç‡∏≠‡∏á Framework ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£")):
    try:
        engine = EngineFactory.get_engine(framework_id)
        return engine.get_switches()
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))

# ==========================================
# 3. Endpoint ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: Chat (‡∏£‡∏∞‡∏ö‡∏∏ Framework ‡πÑ‡∏î‡πâ)
# ==========================================
class ChatRequest(BaseModel):
    message: str
    config: Dict[str, bool]
    framework_id: str = "guardrails_ai"  # <--- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ä‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ
    provider_id: str = "ollama"      # <--- ‡πÄ‡∏û‡∏¥‡πà‡∏°
    model_name: str = "scb10x/typhoon2.5-qwen3-4b"   # <--- ‡πÄ‡∏û‡∏¥‡πà‡∏° (Default)

@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    print(f"üì• Input: {request.message} | Engine: {request.framework_id}")
    
    try:
        active_engine = EngineFactory.get_engine(request.framework_id)
        
        # 2. ‡∏™‡πà‡∏á provider_id ‡πÅ‡∏•‡∏∞ model_name ‡πÑ‡∏õ‡πÉ‡∏´‡πâ Engine
        # (‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ Base Engine ‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ö kwargs ‡πÑ‡∏î‡πâ‡∏Å‡πà‡∏≠‡∏ô ‡∏î‡∏π‡∏Ç‡πâ‡∏≠ 2)
        result = await active_engine.process(
            request.message, 
            request.config, 
            provider_id=request.provider_id, 
            model_name=request.model_name
        )
        # ‡∏Å‡∏£‡∏ì‡∏µ: ‡πÑ‡∏°‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ (Blocked)
        if not result.safe:
            return {
                "status": "blocked",
                "response": "üö´ " + (result.reason or "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏°‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢"),
                "violation": result.violation,
                "reason": result.reason
            }
            
        real_response = result.reason if result.reason else f"AI: ‡∏£‡∏±‡∏ö‡∏ó‡∏£‡∏≤‡∏ö‡∏Ñ‡∏£‡∏±‡∏ö (‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢)"
        
        return {
            "status": "success",
            "response": real_response,
            "violation": None
        }

    except Exception as e:
        print(f"üî• System Error: {e}")
        return {
            "status": "error",
            "response": "System Error: ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö",
            "violation": str(e)
        }
@app.get("/health")
async def health_check():
    """‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ‡πÉ‡∏´‡πâ Frontend ‡∏¢‡∏¥‡∏á‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ Server ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á"""
    return {"status": "ok", "message": "Backend is ready"}    
# ==========================================
# 4. Endpoint ‡πÉ‡∏´‡∏°‡πà: ‡∏Ç‡∏≠‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ LLM Providers (Ollama, GPUStack)
# ==========================================
@app.get("/providers")
async def get_providers():
    return LLMFactory.get_providers()    

# ==========================================
# 5. Endpoint ‡πÉ‡∏´‡∏°‡πà: ‡∏Ç‡∏≠‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ Models ‡∏Ç‡∏≠‡∏á Provider ‡∏ô‡∏±‡πâ‡∏ô‡πÜ
# ==========================================
@app.get("/models/{provider_id}")
async def get_models(provider_id: str):
    try:
        service = LLMFactory.get_service(provider_id)
        models = service.get_models()
        return {"provider": provider_id, "models": models}
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    
class ModelPullRequest(BaseModel):
    provider_id: str
    model_name: str

@app.post("/model/pull")
async def pull_new_model(req: ModelPullRequest):
    try:
        service = LLMFactory.get_service(req.provider_id)
        
        # ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Ollama ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô pull ‡πÑ‡∏ß‡πâ
        if hasattr(service, 'pull_model'):
            success = service.pull_model(req.model_name)
            if success:
                 return {"status": "started", "message": f"Downloading {req.model_name}... Check logs."}
            else:
                 raise HTTPException(status_code=500, detail="Failed to trigger download")
        else:
             return {"status": "skipped", "message": "This provider does not support direct download via API."}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))