from typing import List, Dict
import os
from ..base import BaseGuardEngine, SwitchInfo, GuardResult
from ...llm.factory import LLMFactory

class LlamaGuardEngine(BaseGuardEngine):
    def get_switches(self) -> List[SwitchInfo]:
        return [
            SwitchInfo(key="S1", label="S1: Violent Crimes", default=True),
            SwitchInfo(key="S2", label="S2: Non-Violent Crimes", default=True),
            SwitchInfo(key="S3", label="S3: Sex-Related Crimes", default=True),
            SwitchInfo(key="S4", label="S4: Child Exploitation", default=True),
            SwitchInfo(key="S5", label="S5: Defamation", default=True),
            SwitchInfo(key="S6", label="S6: Specialized Advice", default=True),
            SwitchInfo(key="S7", label="S7: Privacy", default=True),
            SwitchInfo(key="S8", label="S8: Intellectual Property", default=True),
            SwitchInfo(key="S9", label="S9: Indiscriminate Weapons", default=True),
            SwitchInfo(key="S10", label="S10: Hate Speech", default=True),
            SwitchInfo(key="S11", label="S11: Suicide & Self-Harm", default=True),
            SwitchInfo(key="S12", label="S12: Sexual Content", default=True),
            SwitchInfo(key="S13", label="S13: Elections", default=True),
        ]

    async def process(self, message: str, config: Dict[str, bool], **kwargs) -> GuardResult:
        
        # 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Policy (‡∏Å‡∏é) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Llama Guard 3
        # ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏™‡πà‡∏á‡∏Å‡∏é‡∏û‡∏ß‡∏Å‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡∏ö‡∏≠‡∏Å AI ‡∏ß‡πà‡∏≤ "‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏£‡∏ß‡∏à‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏Å‡∏é‡∏û‡∏ß‡∏Å‡∏ô‡∏µ‡πâ‡∏´‡∏ô‡πà‡∏≠‡∏¢"
        # (‡∏ï‡∏±‡∏î‡∏°‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î Token)
        policy = """
<BEGIN UNSAFE CONTENT CATEGORIES>
S1: Violent Crimes. 
S2: Non-Violent Crimes.
S3: Sex-Related Crimes.
S4: Child Sexual Exploitation.
S5: Defamation.
S6: Specialized Advice.
S7: Privacy.
S8: Intellectual Property.
S9: Indiscriminate Weapons.
S10: Hate Speech.
S11: Suicide & Self-Harm.
S12: Sexual Content.
S13: Elections.
<END UNSAFE CONTENT CATEGORIES>
"""
        
        # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡∏ï‡∏≤‡∏°‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô Llama Guard 3
        # ‡∏°‡∏±‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Format ‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ:
        prompt = f"""
<|begin_of_text|><|start_header_id|>user<|end_header_id|>
Task: Check if there is unsafe content in 'User' messages in conversations according to our safety policy with the below categories.

{policy}

<BEGIN CONVERSATION>

User: {message}

<END CONVERSATION>

Provide your safety assessment for User in the above conversation:
- First line must read 'safe' or 'unsafe'.
- If unsafe, a second line must include a comma-separated list of violated categories.
<|eot_id|><|start_header_id|>assistant<|end_header_id|>
"""

        try:
            # 3. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Provider (Ollama ‡∏´‡∏£‡∏∑‡∏≠ GPUStack)
            # ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÉ‡∏ä‡πâ provider ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà User ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏°‡∏≤ ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡πá default ‡πÑ‡∏õ‡∏ó‡∏µ‡πà gpustack
            provider_id = kwargs.get("provider_id", "gpustack")
            
            # ‚ö†Ô∏è ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏• Llama Guard ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ
            # ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ô GPUStack ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô "meta-llama/Llama-Guard-3-1B" 
            # ‡∏´‡∏£‡∏∑‡∏≠‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ Ollama ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô "llama-guard3"
            # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ 'guard' ‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡πà‡∏≠‡∏ô
            llm_service = LLMFactory.get_service(provider_id)
            
            # (Logic ‡πÄ‡∏™‡∏£‡∏¥‡∏°: ‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏• Llama Guard ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)
            available_models = llm_service.get_models()
            target_model = ""
            for m in available_models:
                if "guard" in m.lower():
                    target_model = m
                    break
            
            if not target_model:
                # ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠ default (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÑ‡∏ß‡πâ)
                target_model = "meta-llama/Llama-Guard-3-1B" 

            print(f"üõ°Ô∏è LlamaGuard Checking using model: {target_model}")

            # 4. ‡∏¢‡∏¥‡∏á‡πÑ‡∏õ‡∏ñ‡∏≤‡∏° AI
            response = await llm_service.generate(prompt, model_name=target_model)
            response = response.strip()

            # 5. ‡πÅ‡∏õ‡∏•‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            # Llama Guard ‡∏à‡∏∞‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ "safe" ‡∏´‡∏£‡∏∑‡∏≠ "unsafe\nS1"
            if response.startswith("unsafe"):
                parts = response.split("\n")
                violation_codes = parts[1] if len(parts) > 1 else "Unknown"
                
                # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ User ‡∏õ‡∏¥‡∏î‡∏™‡∏ß‡∏¥‡∏ï‡∏ä‡πå‡∏Å‡∏é‡∏Ç‡πâ‡∏≠‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏ß‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡πà‡∏≤?
                # ‡πÄ‡∏ä‡πà‡∏ô ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ç‡∏≤‡∏õ‡∏¥‡∏î S1 (Violent) ‡πÅ‡∏•‡πâ‡∏ß AI ‡∏ï‡∏≠‡∏ö S1 ‡∏°‡∏≤ ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏•‡πà‡∏≠‡∏¢‡∏ú‡πà‡∏≤‡∏ô
                violated_list = [v.strip() for v in violation_codes.split(",")]
                is_really_unsafe = False
                
                for code in violated_list:
                    # ‡∏ñ‡πâ‡∏≤ config ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ß‡πâ (True) ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏ú‡∏¥‡∏î‡∏à‡∏£‡∏¥‡∏á
                    if config.get(code, True): 
                        is_really_unsafe = True
                        break
                
                if is_really_unsafe:
                    return GuardResult(
                        safe=False, 
                        violation=f"Llama Guard 3 ({violation_codes})", 
                        reason=f"AI ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏°‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏£‡∏´‡∏±‡∏™: {violation_codes}"
                    )

            # ‡∏ñ‡πâ‡∏≤‡∏ï‡∏≠‡∏ö safe ‡∏´‡∏£‡∏∑‡∏≠ ‡∏£‡∏´‡∏±‡∏™‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏™‡∏ß‡∏¥‡∏ï‡∏ä‡πå
            return GuardResult(safe=True)

        except Exception as e:
            print(f"‚ùå Llama Guard Error: {e}")
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏≠‡πã‡∏≠ ‡πÉ‡∏´‡πâ‡∏õ‡∏•‡πà‡∏≠‡∏¢‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏õ‡∏Å‡πà‡∏≠‡∏ô (Fail Open) ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏Å‡πá‡πÑ‡∏î‡πâ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ï‡πà‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢
            return GuardResult(safe=True, reason=f"Llama Guard Error: {e}")