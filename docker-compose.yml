version: '3.8'

services:
  # -------------------------
  # 1. Ollama (Local LLM)
  # -------------------------
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_storage:/root/.ollama
      - ./ollama/entrypoint.sh:/entrypoint.sh
    entrypoint: [ "/bin/bash", "-c", "tr -d '\\r' < /entrypoint.sh | bash" ]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    networks:
      - ai-net

  # -------------------------
  # 2. GPUStack (Manager) âœ¨ à¹€à¸žà¸´à¹ˆà¸¡à¹ƒà¸«à¸¡à¹ˆ
  # -------------------------
  gpustack:
    image: gpustack/gpustack:latest
    ports:
      - "10101:80"
    volumes:
      - gpustack_data:/var/lib/gpustack
    environment:
      - GPUSTACK_USERNAME=admin
      - GPUSTACK_PASSWORD=admin123
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    ipc: host
    networks:
      - ai-net
  # -------------------------
  # 3. Backend (Python API)
  # -------------------------
  backend:
    build:
      context: ./backend
    ports:
      - "8000:8000"
    volumes:
      - ./backend/src:/app/src
    environment:
      - OLLAMA_URL=http://ollama:11434
      - GUARD_ENGINE=guardrails_ai
      - GUARDRAILS_API_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJpSlNlN3ZhNExSbUpxbkZOZUV6VEt0eEZHY1dXdFVuTyIsImFwaUtleUlkIjoiMzEzZGFjNmQtZDE3Yy00OGZkLTllNTItZjdhZDM1N2RjN2U2Iiwic2NvcGUiOiJyZWFkOnBhY2thZ2VzIiwicGVybWlzc2lvbnMiOlsidGhyZWF0X3Rlc3Rlcl9pbnZpdGU6dHJ1ZSJdLCJpYXQiOjE3NzA4NzA2NjcsImV4cCI6NDkyNDQ3MDY2N30.DOijp5oC0pZZFhmrRkXGw00GlNV3dnWfXOgbLtBIofs
      # ðŸ‘‡ à¹à¸à¹‰à¸•à¸£à¸‡à¸™à¸µà¹‰: à¹€à¸£à¸µà¸¢à¸à¸Šà¸·à¹ˆà¸­ Service à¸•à¸£à¸‡à¹† (à¸ à¸²à¸¢à¹ƒà¸™ Port 80)
      - GPUSTACK_URL=http://gpustack:80/v1
    depends_on:
      - ollama
      - gpustack
    networks:
      - ai-net

  # -------------------------
  # 4. Frontend (React)
  # -------------------------
  frontend:
    build:
      context: ./frontend
    ports:
      - "5173:5173"
    volumes:
      - ./frontend/src:/app/src
      - /app/node_modules
    environment:
      - VITE_API_URL=http://localhost:8000
    depends_on:
      - backend
    networks:
      - ai-net

volumes:
  ollama_storage:
  gpustack_data:
    # à¸ªà¸£à¹‰à¸²à¸‡ Volume à¹€à¸à¹‡à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ GPUStack


networks:
  ai-net:
    driver: bridge
